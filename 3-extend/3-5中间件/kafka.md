# 一、Kafka基础

## 1.1 简介
概述：高吞吐、可持久化、可水平扩展的消息系统、存储系统、流式处理平台。
体系结构：Kafka体系由生产者、消费者、broker、zookeeper组成。

## 1.2 相关术语
（1）生产者：生产消息发生给broker；  
（2）broker：Kafka服务节点，接收生产者发送的消息，为消费者提供消费服务，控制消息的生产和消费；  
（3）主题（topic）：保存消息的一个逻辑概念，一个主题可以包含一到多个分区；  
（4）分区（partition）：实际保存消息的结构，在存储层面是一个可追加的log文件，追加消息都会有偏移量（offset），  
通过偏移量保证消息的顺序性；分区副本分leader和ffollower，只有leader副本提供读写服务， follower只负责同步数据。  
（5）消费组：逻辑概念，一个消费者只能属于一个消费组；Kafka的消息是基于消费组广播的；  
（6）消费者：消费者和分区进行绑定，一个消费者可以绑定多个分区，同一个消费组内一个分区只能与一个消费者绑定；  
（7）控制器：管理主题、分区状态，选举分区leader，向其它broker通知元数据；  
（8）AR、ISR、OSR：所有分区副本是AR，和leader保持一定程度同步副本是ISR，和leader同步滞后的副本是OSR；  
只有ISR集合中的副本才能被选举为leader。  
（9）LEO（log end offset）：每一个分区最后一条消息的偏移量 +1；  
（10）高水位（HW）：ISR集合中，最小的LEO值就是HW值，消费者只能消费HW之前的消息；  
（11）zookeeper：保存Kafka元数据信息，协助完成控制器选举，控制器从zk获取主题、分区等元信息；


# 二、生产者理解

## 2.1 生产者发送消息流程
生产消息发送到broker，消息发送会经过如下步骤：  
（1）拦截器；  
（2）序列化器；  
（3）分区器：解析消息发往的分区；  
（4）消息累加器：为每一个分区维护一个队列，对消息进行批量包装（Batch），批量发送提高吞吐量；  
（5）sender（发送线程）：发送消息，并缓存向Broker发送后未收到响应的请求（默认5个）；缓存的  
请求数越多说明broker负载越大，所以应该趋向于使用缓存小的Broker发送消息。

## 2.2 消息发送三种模式
发送即忘、同步、异步

## 2.3 生产端重要参数
acks：指定分区有多少个副本收到消息生产端才确认发送成功，1：leader分区收到即可，0：无需确认，all：ISR所有副本确认；  
max.request.size：发送的消息的最大值；  
retries和retry.backoff.ms：重试次数和重试时间间隔；

# 三、消费者理解

## 3.1 消息消费步骤
（1）配置消费者客户端参数及创建相应的消费者实例。  
（2）订阅主题。  
（3）拉取消息并消费。  
（4）提交消费位移。  
（5）关闭消费者实例。

## 3.2 消费端端术语
（1）必要参数： broker地址清单bootstrap.servers；所属消费组group.id； key.deserializer 和 value.deserializer反序列化器。  
（2）消息消费：消息消费有推、拉两种模式，Kafka是基于拉模式的，客户端轮询调用poll方法获取消息。  
（3）位移提交：Kafka使用内部主题__consumer_offsets持久化保存位移提交；默认开启自动位移提交。  
（4）自动位移提交：**Kafka的自动位移提交不是每消费一次提交一次，而是定时提交，默认每隔5秒在poll方法中执行提交。**  
（5）手动提交：可以指定提交的偏移量和分区，默认提交本次拉取消息的偏移量。  
（6）同步、异步提交：手动提交分同步、异步，同步会阻塞消费组、异步不会，异步实现复杂但能提高整体的消费性能。  
（7）暂停和恢复消费：pause（）方法暂停消费、resume（)方法恢复消费。  
（8）**多线程实现：KafkaConsumer是非线程安全的，为了提高消费效率可以一个KafkaConsumer使用一个线程去消费一个分区的消息，  
如果一个KafkaConsumer使用多线程消费的话，对于位移提交和顺序性的保证会变得复杂。**  
（9）再均衡：当消费者或分区发生变化时 重新分配消费组和分区的关系，再均衡期间消费组不可用。

## 3.3 消息丢失和重复消费
### 生产端导致消息丢失
如果生产者没有进行消息发送确认，可能导致消息丢失。

### 消费端导致丢失和重复消费
因为poll方法一次是拉取的一批消息，offset区间\[0,10\],，如果消费者在处理消息时崩溃，恢复后重新拉取消息；  
此时如果从0偏移量重新拉取消息会产生重复消费，从10偏移量拉取消息会产生消息丢失。


### **解决消息丢失和重复消费**
（1）生产端使用确认机制避免消息丢失。  
（2）从业务的角度为每个消息添加一个递增的序号，拉取消息保证不存在丢失，消费的时候根据消息的序号和已经消费（通过redis、数据库保存已经消费的序号）  
的消息序号进行比较，如果已经处理过则放弃。此处可以使用布隆过滤器 保证消息肯定没被消费过。  
（3）极端情况可以每次poll只拉取一条消息。



# 四、主题与分区
分区

# 五、日志存储
## 文件布局
Log：每个分区对应一个日志文件Log；  
LogSegment：为了防止Log文件过大，每个Log分为多个日志分段，消息追加在最后一个LogSegment；  
索引文件：为了便于消息检索，每个LogSegment都对应两个索引文件，偏移量索引文件（以.index结尾）和时间戳索引文件（以.timeindex结尾）。

## 日志索引
偏移量索引文件保存的是偏移量和物理地址的映射关系，便于定位消息的物理地址；时间戳索引文件是根据时间戳来查找偏移量。  
稀疏索引：Kafka索引文件使用稀疏索引，并不少每个消息都有对应的索引项，而是当写入一定量的数据（默认4KB）时在偏移量索引文件  
和时间戳索引文件添加一个索引，索引文件单调递增。  
索引查找：当查询偏移量时，使用二分来定位偏移量的位置，如果偏移量不在索引文件，则返回小于指定偏移量的最大偏移量索引项。



# 六、深入理解客户端
## 6.1 分区分配策略
RangeAssignor分配策略：消费者数和分区数整除获取一个跨度，使用这个跨度尽可能保证平均分配。  
RoundRobinAssignor分配策略：消费组内所有消费者和消费者订阅的所有分区 按字典序排序，然后轮询依次分配。  
StickyAssignor分配策略：当发生重分配时，尽可能保证上一次的分配结果。  
自定义分配策略：实现org.apache.kafka.clients.consumer.internals.PartitionAssignor接口。

## 6.2消费者协调器和组协调器
消费组被拆分成多个子集，每个子集对应服务端有一个GroupCoordinator进行管理；消费者客户端有一个ConsumerCoordinator  
与GroupCoordinator进行交互，两者协调完成再均衡操作。

### 如下情形会发生再均衡操作：
（1）消费者加入、宕机或退（消费者向GroupCoordinator发送心跳类维持 与消费组的从属关系）；  
（2）消费组对应的GroupCoordinator节点发生变更；  
（3）消费组订阅的任一主题或主题的分区数发生变化。

### 再均衡步骤（举例新的消费者加入）
（1）消费者确定 自身所属消费组对应的GroupCoordinator所在的broker，并与之建立通信连接；
（2）消费者向对应的GroupCoordinator发送加入请求，GroupCoordinator会从消费组中选出一个leader消费者，  
并确定分区分配策略（每个消费者都可以选择分区分配策略，得票最多的策略是最终策略），GroupCoordinator在确定策略  
后将相关信息发送给leader消费者，由消费者完成具体的分配。  
（3）leader消费者通过GroupCoordinator间接的完成分区分配工作。  
（4）使用_consumer_offsets恢复消费位置，消费者恢复工作。

再均衡总结：broker节点的GroupCoordinator和消费者的ConsumerCoordinator交互实现再均衡。

## 6.3 幂等、事务
幂等：引入序列号保证生产者发送消息的幂等，每次发送消息broker序列号都会递增1，且只能递增；  
如上一次序列号为10，本次发送消息序列号为10则直接抛弃、为12则出现消息丢失 抛出异常；必须为11。

事务：幂等只能保证单个分区写入的原子性，事务保证对多个分区写入的原子性。

**Kafka提供的幂等和事务都是保证生产者写入的原子性，无法保证消费端。**




# 七、深入服务端
## 7.1 时间轮
Kafka借助时间轮完成延时操作；Netty、quartz、zookeeper都有使用时间轮。

原理简述：时间轮是一个存储定时任务的环形队列；时间轮的格数是固定的wheelSize表示，基本时间跨度为tickMs，  
总体时间跨度interval=tickMs * wheelSize。时间轮的每个节点都维护一个TimerTaskList任务列表。  
若cur时刻插入一个定时n刻度的任务，那么这个任务会保存在 cur + n刻度的TimerTaskList任务列表中。

单层时间轮因为"容量"原因无法处理溢出时间轮的任务；所以时间轮引入层级时间轮处理更长周期的任务。

## 延时操作
## 控制器
（1）broker节点会有一个broker被选举为控制器，控制器负责对所有的主题和分区进行管理（选举分区leader副本）；  
（2）控制器会监听zookeeper，当主题、分区、broker等信息发送变化时，由控制器去通知其它的broker。**在老版本中没有控制器的概念，  
每个broker都去监听zookeeper，可能导致羊群效应**

控制器选举：依赖zookeeper的临时节点。  
分区leader选举：AR集合中的第一个副本，并且这个副本术语ISR。


# 八、面试问题

## 1、顺序消费
Kafka保证同一分区的消息的顺序消费
## 2、保证幂等
日志记录；
业务场景添加消息的唯一ID，通过消费的时候，业务处理成功后才提交；如果消息的ID已经处理过，则不再消费。

## 3、消息丢失
发送端消息丢失（follower节点未同步，leader挂掉），可以使用发送端的确认机制避免。
消费端消息丢失（消息未处理，自动提交位移），关闭位移自动提交。

## 4、Kafka死信队列
Kafka本身不支持死信队列；可以自己实现相关功能；
当消息处理失败后，将消息投递到重试topic1并添加重试次数的属性；
消费者也订阅topic1，然后每次处理消息时把重试次数加1；
当重试次数达到约定值时，将消息持久化。

## 5、Kafka如何保证高性能、高吞吐量
（1）基于磁盘的顺序读写；
（2）页缓存：读数据时候先读内存缓存，有直接返回，没有则去磁盘读取然后保存在内存；  
写的时候先写到页缓存，页缓存满了后系统调用（flush、pdflush等）会自动把页缓存刷回磁盘。  
系统调用刷回磁盘是有延迟的，所以如果这段时间broker挂了，有可能导致页缓存数据丢失。  
所以Kafka也提供了同步刷盘的方法，但是同步刷盘会导致吞吐量降低。

**一般不使用同步刷盘机制避免消息丢失，partition本身一主多从也是为了保证可靠性。开发者需要在**  
**吞吐量和可靠性直接做权衡。**


（3）零拷贝：send file（系统调用），常规的IO读调用需要将数据从磁盘copy to系统内核，
系统内核copy to应用内存；写的时候还需要将数据从应用内存copy to内核，最后再从内核copy到网卡；
传统IO经历来4次copy，4次上下文切换；零拷贝只需要2次copy、2次上下文切换。
[参考](https://zhuanlan.zhihu.com/p/85571977)
（4）消息的发送、拉取会打包处理

## 6、再均衡（rebalance）
当有消费者加入、移除，topic变化、分区数量变化发生时候会发生再均衡。  
再均衡操作是由broker的GroupCoordinator和消费端的CustomerCoordinator交互去执行的；最终执行者是由
选举出来的leader消费者去处理的。

## 7、提高消费效率
（1）如果消费者少于队列，可以多创建几个消费者；保证一个消费者对应一个队列；  
（2）如果速度还是不够，那么消费端可以开启多线程消费；但是多线程消费的位移提交、顺序控制太复杂；  
一般不建议使用。

## 8、时间轮
时间轮由一个环形链表表示，节点的个数表示刻度，每个节点保存一个任务列表。  
单层时间轮"容量"有限，使用层级时间轮处理更长周期的任务。  
Kafka使用DelayQueue推动时间轮。


